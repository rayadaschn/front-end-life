---
title: æ£€æŸ¥å¤šè¯­è¨€é‡å¤
icon: nodeJS
date: 2024-11-14
category:
  - javascript
tag:
  - node
---

æœ€è¿‘éœ€è¦æ£€æŸ¥å¤šè¯­è¨€æ–‡ä»¶ä¸­æ˜¯å¦æœ‰é‡å¤çš„ keyï¼Œäºæ˜¯å†™äº†ä¸€ä¸ª Node.js è„šæœ¬æ¥å®ç°è¿™ä¸ªåŠŸèƒ½ã€‚è¿™ä¸ªè„šæœ¬ä¼šéå†æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ JSON æ–‡ä»¶ï¼Œæ£€æŸ¥æ¯ä¸ªæ–‡ä»¶ä¸­çš„ key æ˜¯å¦æœ‰é‡å¤ï¼Œå¹¶å°†ç»“æœè¾“å‡ºåˆ°æ§åˆ¶å°ã€‚åŒæ—¶ï¼Œè„šæœ¬è¿˜ä¼šå°†æ‰€æœ‰ key å­˜å…¥ä¸€ä¸ªç¼“å­˜æ–‡ä»¶ä¸­ï¼Œä»¥ä¾¿ä¸‹æ¬¡è¿è¡Œæ—¶å¯ä»¥å¿«é€ŸæŸ¥è¯¢ã€‚

```js
const fs = require('fs')
const path = require('path')

const cacheFilePath = path.join(__dirname, 'temp/i18n_keys_cache.json')

// æ£€æŸ¥å¹¶åˆ›å»ºç¼“å­˜ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
const cacheDir = path.dirname(cacheFilePath)
if (!fs.existsSync(cacheDir)) {
  fs.mkdirSync(cacheDir, { recursive: true })
}

// è·å–ä¼ å…¥çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
const files = process.argv.slice(2)
console.info('ğŸš€ ~ Starting file check:', files)

// åŠ è½½ç¼“å­˜å¹¶å°†æ‰€æœ‰ key å­˜å…¥ Set ä»¥æé«˜æŸ¥è¯¢æ•ˆç‡
function loadCache() {
  if (fs.existsSync(cacheFilePath)) {
    const cacheContent = fs.readFileSync(cacheFilePath, 'utf8')
    const cache = JSON.parse(cacheContent)
    return {
      cache,
      allKeysSet: new Set(Object.values(cache).flat()), // ç”¨ Set å­˜å‚¨æ‰€æœ‰ key
    }
  }
  return { cache: {}, allKeysSet: new Set() }
}

// ä¿å­˜å…±äº«ç¼“å­˜
function saveCache(cache) {
  fs.writeFileSync(cacheFilePath, JSON.stringify(cache, null, 2), 'utf8')
}

// è·å– JSON å¯¹è±¡çš„æœ€åä¸€çº§ key
function getLastLevelKeys(obj) {
  const keys = []
  function recurse(o) {
    if (typeof o !== 'object' || o === null) return
    for (const key in o) {
      if (typeof o[key] === 'object') {
        recurse(o[key])
      } else {
        keys.push(key)
      }
    }
  }
  recurse(obj)
  return keys
}

// æ£€æŸ¥é‡å¤ key å¹¶æ›´æ–°ç¼“å­˜
function checkForDuplicateKeys(files) {
  const { cache, allKeysSet } = loadCache()
  const duplicateKeys = new Set()

  files.forEach((file) => {
    const fileName = path.basename(file, '.json') // ä½¿ç”¨æ–‡ä»¶åä½œä¸ºé”®
    const filePath = path.resolve(file)
    const content = fs.readFileSync(filePath, 'utf8')
    const jsonData = JSON.parse(content)

    const keys = getLastLevelKeys(jsonData)

    // ä»ç¼“å­˜ä¸­åˆ é™¤æ—§çš„ key
    if (cache[fileName]) {
      cache[fileName].forEach((key) => allKeysSet.delete(key)) // ä» Set ä¸­åˆ é™¤
      delete cache[fileName]
    }

    // æ£€æŸ¥é‡å¤ keyï¼Œå¹¶è®°å½•
    let hasDuplicate = false
    keys.forEach((key) => {
      if (allKeysSet.has(key)) {
        duplicateKeys.add(key)
        hasDuplicate = true
      }
    })

    // æ›´æ–°ç¼“å­˜ï¼šä»…åœ¨æ²¡æœ‰é‡å¤æ—¶ä¿å­˜æ–° key
    if (!hasDuplicate) {
      cache[fileName] = keys
      keys.forEach((key) => allKeysSet.add(key)) // æ·»åŠ æ–° key åˆ° Set
    }
  })

  saveCache(cache) // ä¿å­˜æ›´æ–°åçš„å…±äº«ç¼“å­˜
  return [...duplicateKeys]
}

// æ£€æŸ¥æ–‡ä»¶
const duplicates = checkForDuplicateKeys(files)
if (duplicates.length) {
  console.error('Duplicate keys found:', duplicates)
  process.exit(1) // é€€å‡ºå¹¶é˜»æ­¢æäº¤
} else {
  console.info('ğŸš€ ~ i18n key check complete, no duplicates found')
}
```
