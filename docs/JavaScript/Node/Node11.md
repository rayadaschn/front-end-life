---
title: æ£€æŸ¥å¤šè¯­è¨€é‡å¤
icon: nodeJS
date: 2024-11-14
category:
  - javascript
tag:
  - node
---

æœ€è¿‘éœ€è¦æ£€æŸ¥å¤šè¯­è¨€æ–‡ä»¶ä¸­æ˜¯å¦æœ‰é‡å¤çš„ keyï¼Œäºæ˜¯å†™äº†ä¸€ä¸ª Node.js è„šæœ¬æ¥å®ç°è¿™ä¸ªåŠŸèƒ½ã€‚

è¿™ä¸ªè„šæœ¬ä¼šåœ¨ git æäº¤ä»£ç æ—¶ï¼Œå¯¹æäº¤çš„å¤šè¯­è¨€æ–‡ä»¶è¿›è¡Œæ ¡éªŒã€‚é€šè¿‡éå†æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ JSON æ–‡ä»¶ï¼Œæ£€æŸ¥æ¯ä¸ªæ–‡ä»¶ä¸­çš„ key æ˜¯å¦æœ‰é‡å¤ï¼Œå¹¶å°†ç»“æœè¾“å‡ºåˆ°æ§åˆ¶å°ã€‚åŒæ—¶ï¼Œè„šæœ¬è¿˜ä¼šå°†æ‰€æœ‰ key å­˜å…¥ä¸€ä¸ªç¼“å­˜æ–‡ä»¶ä¸­ï¼Œä»¥ä¾¿ä¸‹æ¬¡è¿è¡Œæ—¶å¯ä»¥å¿«é€ŸæŸ¥è¯¢ã€‚

## å®ç°é€»è¾‘

ç†è®ºä¾æ®ï¼šç”±äº `lint-staged` ä¼šå°†**æš‚å­˜åŒºä¸­è¢«ä¿®æ”¹çš„æ–‡ä»¶è·¯å¾„**ä½œä¸ºå‚æ•°ä¼ å…¥å®šä¹‰çš„è„šæœ¬ã€‚è¿™æ„å‘³ç€å¯ä»¥åœ¨ `lint-staged` ä¸­é…ç½®çš„å‘½ä»¤ä¸­ç›´æ¥è®¿é—®æäº¤çš„æ–‡ä»¶åˆ—è¡¨ï¼Œè€Œä¸éœ€è¦æ‰‹åŠ¨æŒ‡å®šæ–‡ä»¶è·¯å¾„ã€‚

å› æ­¤ `const files = process.argv.slice(2);` å°±æ˜¯è·å–æäº¤çš„æ–‡ä»¶åˆ—è¡¨ï¼Œç„¶åé€šè¿‡ `fs.readFileSync` è¯»å–æ–‡ä»¶å†…å®¹ï¼Œæœ€åé€šè¿‡ `getLastLevelKeys` è·å–æ–‡ä»¶ä¸­çš„æ‰€æœ‰ keyï¼Œå¹¶æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„ keyã€‚

### 1. **åŸºæœ¬è·¯å¾„å’Œç›®å½•åˆå§‹åŒ–**

```js
const cacheFilePath = path.join(__dirname, 'temp/i18n_keys_cache.json')
const cacheDirPath = path.join(__dirname, '../src/i18n/zh') // æŒ‡å®šä¸­æ–‡ç›®å½•
```

- `cacheFilePath` å®šä¹‰ç¼“å­˜æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºä¿å­˜ä¹‹å‰æ£€æŸ¥è¿‡çš„é”®ï¼‰ã€‚
- `cacheDirPath` æŒ‡å®š `zh` æ–‡ä»¶å¤¹è·¯å¾„ï¼Œä½œä¸ºå¤šè¯­è¨€ JSON æ–‡ä»¶çš„å­˜å‚¨ç›®å½•ï¼Œç”¨äºåˆå§‹åŒ–ç¼“å­˜æ–‡ä»¶ã€‚

### 2. **åˆ›å»ºç¼“å­˜ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰**

```js
const cacheDir = path.dirname(cacheFilePath)
if (!fs.existsSync(cacheDir)) {
  fs.mkdirSync(cacheDir, { recursive: true })
}
```

- æ£€æŸ¥å¹¶åˆ›å»ºå­˜å‚¨ç¼“å­˜æ–‡ä»¶çš„ `temp` ç›®å½•ï¼Œä»¥ç¡®ä¿ç¼“å­˜æ–‡ä»¶çš„å­˜æ”¾ä½ç½®å­˜åœ¨ã€‚

### 3. **åŠ è½½ä¼ å…¥çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨**

```js
const files = process.argv.slice(2)
console.info('ğŸš€ ~ Starting file check:', files)
```

- `process.argv.slice(2)` ç”¨äºè·å–å‘½ä»¤è¡Œä¼ å…¥çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œæ’é™¤ Node å’Œè„šæœ¬æœ¬èº«çš„è·¯å¾„ã€‚`files` æ•°ç»„å°†è¢«ä¼ å…¥åç»­æ£€æŸ¥å‡½æ•°ã€‚

### 4. **åŠ è½½ç¼“å­˜å¹¶ç”Ÿæˆæ‰€æœ‰é”®çš„ Set é›†åˆ**

```js
function loadCache() {
  if (fs.existsSync(cacheFilePath)) {
    const cacheContent = fs.readFileSync(cacheFilePath, 'utf8')
    const cache = JSON.parse(cacheContent)
    return {
      cache,
      allKeysSet: new Set(Object.values(cache).flat()), // å°†ç¼“å­˜çš„é”®å­˜å…¥ Set
    }
  }
  const cache = initializeCache()
  saveCache(cache)
  return { cache, allKeysSet: new Set(Object.values(cache).flat()) }
}
```

- æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™è¯»å–å¹¶è§£æ JSON å†…å®¹ã€‚
- `allKeysSet` æ˜¯ä¸€ä¸ª Set å¯¹è±¡ï¼Œç”¨äºé«˜æ•ˆå­˜å‚¨å¹¶æŸ¥è¯¢æ‰€æœ‰é”®ï¼Œé¿å…é‡å¤ã€‚
- è‹¥ç¼“å­˜ä¸å­˜åœ¨ï¼Œé€šè¿‡ `initializeCache()` åˆå§‹åŒ–ï¼Œå¹¶å°†æ‰€æœ‰çš„é”®æ·»åŠ åˆ° `allKeysSet`ã€‚

### 5. **ä»æŒ‡å®šç›®å½•åˆå§‹åŒ–ç¼“å­˜**

```js
function initializeCache() {
  const cache = {}
  const files = fs
    .readdirSync(cacheDirPath)
    .filter((file) => file.endsWith('.json'))

  files.forEach((file) => {
    const fileName = path.basename(file, '.json')
    const filePath = path.join(cacheDirPath, file)
    const content = fs.readFileSync(filePath, 'utf8')
    const jsonData = JSON.parse(content)

    cache[fileName] = getLastLevelKeys(jsonData) // è·å– JSON çš„æœ€åä¸€çº§é”®
  })

  console.info('ğŸš€ ~ Initialized cache from zh directory with files:', files)
  return cache
}
```

- `initializeCache()` éå† `zh` ç›®å½•ä¸‹çš„æ‰€æœ‰ JSON æ–‡ä»¶ã€‚
- å¯¹æ¯ä¸ªæ–‡ä»¶æå–æœ€åä¸€çº§çš„é”®ï¼ˆç”¨ `getLastLevelKeys()` è·å–ï¼‰ï¼Œå¹¶ä»¥æ–‡ä»¶åä½œä¸ºç¼“å­˜ä¸­çš„é”®ï¼Œä¾¿äºå®šä½å’Œæ›´æ–°ã€‚

### 6. **è·å– JSON å¯¹è±¡çš„æœ€åä¸€çº§é”®**

```js
function getLastLevelKeys(obj) {
  const keys = []
  function recurse(o) {
    if (typeof o !== 'object' || o === null) return
    for (const key in o) {
      if (typeof o[key] === 'object') {
        recurse(o[key])
      } else {
        keys.push(key)
      }
    }
  }
  recurse(obj)
  return keys
}
```

- `getLastLevelKeys` æ˜¯é€’å½’å‡½æ•°ï¼Œéå†å¯¹è±¡å¹¶æå–å…¶æœ€åº•å±‚çš„é”®ï¼Œç”¨äºé¿å…åµŒå¥—å¯¹è±¡å½±å“ã€‚

### 7. **æ£€æŸ¥é‡å¤é”®å¹¶æ›´æ–°ç¼“å­˜**

```js
function checkForDuplicateKeys(files) {
  const { cache, allKeysSet } = loadCache()
  const duplicateKeys = new Set()

  files.forEach((file) => {
    const fileName = path.basename(file, '.json')
    const filePath = path.resolve(file)
    const content = fs.readFileSync(filePath, 'utf8')
    const jsonData = JSON.parse(content)

    const keys = getLastLevelKeys(jsonData)

    if (cache[fileName]) {
      cache[fileName].forEach((key) => allKeysSet.delete(key))
      delete cache[fileName]
    }

    let hasDuplicate = false
    keys.forEach((key) => {
      if (allKeysSet.has(key)) {
        duplicateKeys.add(key)
        hasDuplicate = true
      }
    })

    if (!hasDuplicate) {
      cache[fileName] = keys
      keys.forEach((key) => allKeysSet.add(key))
    }
  })

  saveCache(cache)
  return [...duplicateKeys]
}
```

- `checkForDuplicateKeys` éå†æ¯ä¸ªæ–‡ä»¶ï¼Œæ£€æŸ¥å…¶é”®æ˜¯å¦åœ¨ `allKeysSet` ä¸­å­˜åœ¨ã€‚
- å¦‚æœå‘ç°é‡å¤é”®ï¼Œè®°å½•åˆ° `duplicateKeys`ã€‚
- æ²¡æœ‰é‡å¤é”®æ—¶ï¼Œå°†æ–‡ä»¶çš„æ–°é”®æ›´æ–°è‡³ `cache` å¹¶æ·»åŠ åˆ° `allKeysSet`ã€‚

### 8. **æ£€æŸ¥æ–‡ä»¶å¹¶è¾“å‡ºç»“æœ**

```js
const duplicates = checkForDuplicateKeys(files)
if (duplicates.length) {
  console.error('Duplicate keys found:', duplicates)
  process.exit(1) // é˜»æ­¢æäº¤
} else {
  console.info('ğŸš€ ~ i18n key check complete, no duplicates found')
}
```

- æ£€æŸ¥å®Œæ¯•åï¼Œè‹¥å‘ç°é‡å¤é”®ï¼Œå°†è¾“å‡ºé”™è¯¯ä¿¡æ¯å¹¶é˜»æ­¢æäº¤ï¼ˆé€šè¿‡ `process.exit(1)` é€€å‡ºï¼‰ã€‚
- è‹¥æ— é‡å¤é”®ï¼Œè¾“å‡ºæˆåŠŸä¿¡æ¯å¹¶ç»“æŸã€‚

## ä»£ç å±•ç¤º

ä»¥ä¸‹æ˜¯è„šæœ¬çš„ä»£ç ï¼š

```js
const fs = require('fs')
const path = require('path')

const cacheFilePath = path.join(__dirname, 'temp/i18n_keys_cache.json')
const cacheDirPath = path.join(__dirname, '../src/i18n/zh') // æŒ‡å®šä¸­æ–‡ç›®å½•, ä¸»è¦ç»´æŠ¤å¤šè¯­è¨€åŸºç¡€ç‰ˆæœ¬

// æ£€æŸ¥å¹¶åˆ›å»ºç¼“å­˜ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
const cacheDir = path.dirname(cacheFilePath)
if (!fs.existsSync(cacheDir)) {
  fs.mkdirSync(cacheDir, { recursive: true })
}

// è·å–ä¼ å…¥çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
const files = process.argv.slice(2)
console.info('ğŸš€ ~ Starting file check:', files)

// åŠ è½½ç¼“å­˜å¹¶å°†æ‰€æœ‰ key å­˜å…¥ Set ä»¥æé«˜æŸ¥è¯¢æ•ˆç‡
function loadCache() {
  if (fs.existsSync(cacheFilePath)) {
    const cacheContent = fs.readFileSync(cacheFilePath, 'utf8')
    const cache = JSON.parse(cacheContent)
    return {
      cache,
      allKeysSet: new Set(Object.values(cache).flat()), // ç”¨ Set å­˜å‚¨æ‰€æœ‰ key
    }
  }
  // åˆå§‹åŒ–ç¼“å­˜æ–‡ä»¶
  const cache = initializeCache()
  saveCache(cache)
  return { cache, allKeysSet: new Set(Object.values(cache).flat()) }
}

// é€šè¿‡åŠ è½½ç»´æŠ¤ç›®å½•ä¸­çš„æ‰€æœ‰ JSON æ–‡ä»¶æ¥åˆå§‹åŒ–ç¼“å­˜
function initializeCache() {
  const cache = {}
  const files = fs
    .readdirSync(cacheDirPath)
    .filter((file) => file.endsWith('.json'))

  files.forEach((file) => {
    const fileName = path.basename(file, '.json')
    const filePath = path.join(cacheDirPath, file)
    const content = fs.readFileSync(filePath, 'utf8')
    const jsonData = JSON.parse(content)

    // å°†æ–‡ä»¶çš„æœ€åä¸€çº§é”®æ·»åŠ åˆ°ç¼“å­˜ä¸­
    cache[fileName] = getLastLevelKeys(jsonData)
  })

  console.info('ğŸš€ ~ Initialized cache from zh directory with files:', files)
  return cache
}

// ä¿å­˜å…±äº«ç¼“å­˜
function saveCache(cache) {
  fs.writeFileSync(cacheFilePath, JSON.stringify(cache, null, 2), 'utf8')
}

// è·å– JSON å¯¹è±¡çš„æœ€åä¸€çº§ key
function getLastLevelKeys(obj) {
  const keys = []
  function recurse(o) {
    if (typeof o !== 'object' || o === null) return
    for (const key in o) {
      if (typeof o[key] === 'object') {
        recurse(o[key])
      } else {
        keys.push(key)
      }
    }
  }
  recurse(obj)
  return keys
}

// æ£€æŸ¥é‡å¤ key å¹¶æ›´æ–°ç¼“å­˜
function checkForDuplicateKeys(files) {
  const { cache, allKeysSet } = loadCache()
  const duplicateKeys = new Set()

  files.forEach((file) => {
    const fileName = path.basename(file, '.json') // ä½¿ç”¨æ–‡ä»¶åä½œä¸ºé”®
    const filePath = path.resolve(file)
    const content = fs.readFileSync(filePath, 'utf8')
    const jsonData = JSON.parse(content)

    const keys = getLastLevelKeys(jsonData)

    // ä»ç¼“å­˜ä¸­åˆ é™¤æ—§çš„ key
    if (cache[fileName]) {
      cache[fileName].forEach((key) => allKeysSet.delete(key)) // ä» Set ä¸­åˆ é™¤
      delete cache[fileName]
    }

    // æ£€æŸ¥é‡å¤ keyï¼Œå¹¶è®°å½•
    let hasDuplicate = false
    keys.forEach((key) => {
      if (allKeysSet.has(key)) {
        duplicateKeys.add(key)
        hasDuplicate = true
      }
    })

    // æ›´æ–°ç¼“å­˜ï¼šä»…åœ¨æ²¡æœ‰é‡å¤æ—¶ä¿å­˜æ–° key
    if (!hasDuplicate) {
      cache[fileName] = keys
      keys.forEach((key) => allKeysSet.add(key)) // æ·»åŠ æ–° key åˆ° Set
    }
  })

  saveCache(cache) // ä¿å­˜æ›´æ–°åçš„å…±äº«ç¼“å­˜
  return [...duplicateKeys]
}

// æ£€æŸ¥æ–‡ä»¶
const duplicates = checkForDuplicateKeys(files)
if (duplicates.length) {
  console.error('Duplicate keys found:', duplicates)
  process.exit(1) // é€€å‡ºå¹¶é˜»æ­¢æäº¤
} else {
  console.info('ğŸš€ ~ i18n key check complete, no duplicates found')
}
```
